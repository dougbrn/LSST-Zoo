{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from net import LSSTNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load parameters\n",
    "params_df = pd.read_csv(\"ML_param.csv\")\n",
    "# Just doing what the repo did\n",
    "del params_df['coord_dec'] \n",
    "del params_df['coord_ra']\n",
    "del params_df['id']\n",
    "del params_df['parent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load classfication data\n",
    "data_df = pd.read_csv(\"../classifications/lsst_run_one.csv\")\n",
    "data_df.head()\n",
    "classify_df = data_df.loc[data_df['workflow_name'] == \"Difference Imaging Classifier\"]\n",
    "\n",
    "image_class = np.zeros(classify_df.shape[0], dtype='int, object')\n",
    "idx = 0\n",
    "for _, row in classify_df.iterrows():\n",
    "    s_data = json.loads(row.subject_data) #Subject Data\n",
    "    s_data = s_data.get(list(s_data.keys())[0])\n",
    "    # cut \"/home/......./cutout\" and \".png\"\n",
    "    image_num = s_data.get(list(s_data.keys())[1])[47:-4]\n",
    "    # annotations\n",
    "    a_data = json.loads(row.annotations)[0]\n",
    "    classification = a_data['value']\n",
    "    image_class[idx] = (int(image_num), classification)\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new classification column, init with None\n",
    "params_df = params_df.assign(Classification=Series(np.full(params_df.shape[0], None)))\n",
    "for image in image_class:\n",
    "    params_df.loc[image[0], \"Classification\"] = image[1]\n",
    "# drop the rows with no classification\n",
    "df = params_df[params_df[\"Classification\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some columns\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().all():\n",
    "        del df[col]   \n",
    "    elif df[col].dtype != 'object' and np.mean(df[col]) == np.inf:\n",
    "        del df[col]\n",
    "    elif \"flag\" in col: #Flags don't contribute to ML based on initial testing\n",
    "        del df[col]\n",
    "    \n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, dev, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dipole': 0, 'Possible Transient': 1, 'Subtraction Error': 2, 'Possible Variable Star': 3, 'Pixel Artifact': 4, 'Noise': 5}\n"
     ]
    }
   ],
   "source": [
    "# shuffle data\n",
    "df.sample(frac=1)\n",
    "\n",
    "# normalize\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"float64\" or df[col].dtype == \"int64\":\n",
    "        df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "\n",
    "# get rid of (super) low variance features\n",
    "selector = VarianceThreshold(0.01)\n",
    "training = selector.fit_transform(df.drop(columns=['Classification']))\n",
    "labels = df['Classification']\n",
    "\n",
    "length = training.shape[0]\n",
    "train_split = int(length * 0.7)\n",
    "dev_split = int(length * 0.9)\n",
    "\n",
    "train_X = training[0 : train_split]\n",
    "dev_X = training[train_split : dev_split]\n",
    "test_X = training[dev_split:]\n",
    "\n",
    "# type to vectors\n",
    "label_dict = dict()\n",
    "trans_dict = dict()\n",
    "for i, l in enumerate(labels.unique()):\n",
    "    label_dict[l] = i\n",
    "    trans_dict[i] = l\n",
    "\n",
    "    \n",
    "print(label_dict)\n",
    "    \n",
    "Y = []\n",
    "for i in labels:\n",
    "    Y.append(label_dict[i])\n",
    "    \n",
    "    \n",
    "train_y = Y[0 : train_split]\n",
    "dev_y = Y[train_split : dev_split]\n",
    "test_y = Y[dev_split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSSTNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LSSTNet, self).__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "                         nn.Linear(73, 60),\n",
    "                         nn.Linear(60, 45),\n",
    "                         nn.BatchNorm1d(45, momentum=0.5),\n",
    "                         nn.Linear(45, 30),\n",
    "                         nn.Linear(30, 20),\n",
    "                         nn.BatchNorm1d(20, momentum=0.5),\n",
    "                         nn.Linear(20, 15),\n",
    "                         nn.Linear(15, 10),\n",
    "                         nn.Linear(10, 6))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Use relu\n",
    "        \"\"\"\n",
    "        return F.log_softmax(self.model(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LSSTNet().double()\n",
    "\n",
    "# optim and loss\n",
    "optim = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
    "critetion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need variable wrapper\n",
    "X = Variable(torch.from_numpy(train_X).contiguous())\n",
    "y = Variable(torch.from_numpy(np.asarray(train_y)).contiguous()).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  0  loss:  1.8377871365580016\n",
      "t:  100  loss:  1.5178732219140585\n",
      "t:  200  loss:  1.2915377409608477\n",
      "t:  300  loss:  1.1227400822000113\n",
      "t:  400  loss:  0.9821514923922263\n",
      "t:  500  loss:  0.8678167566242215\n",
      "t:  600  loss:  0.7821163072439973\n",
      "t:  700  loss:  0.717887112670382\n",
      "t:  800  loss:  0.668026117151191\n",
      "t:  900  loss:  0.6261360412035483\n",
      "t:  1000  loss:  0.5889225004639783\n",
      "t:  1100  loss:  0.5551043674802563\n",
      "t:  1200  loss:  0.52604187553763\n",
      "t:  1300  loss:  0.5026572136581108\n",
      "t:  1400  loss:  0.48313467578057945\n",
      "t:  1500  loss:  0.46618286414199395\n",
      "t:  1600  loss:  0.457715709774658\n",
      "t:  1700  loss:  0.4391918073746846\n",
      "t:  1800  loss:  0.4297531045441598\n"
     ]
    }
   ],
   "source": [
    "T = 1900\n",
    "# run 500 times\n",
    "for t in range(T):\n",
    "    # forward\n",
    "    y_pred = net(X)\n",
    "    loss = critetion(y_pred, y)\n",
    "    # Zero the gradients before running the backward pass.\n",
    "    net.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if t % 100 == 0:\n",
    "        print(\"t: \", t, \" loss: \", loss.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dev testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "development_X = Variable(torch.from_numpy(dev_X).contiguous())\n",
    "development_y = Variable(torch.from_numpy(np.asarray(dev_y)).contiguous()).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_pred = net(development_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5529023410887203\n"
     ]
    }
   ],
   "source": [
    "print(critetion(dev_pred, development_y).data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n",
      "0.797979797979798\n"
     ]
    }
   ],
   "source": [
    "# check how many we got right:\n",
    "correct = 0\n",
    "for ii, pred in enumerate(dev_pred.data):\n",
    "    i = np.argmax(pred)\n",
    "    if i == dev_y[ii]:\n",
    "        correct += 1\n",
    "        \n",
    "        \n",
    "print(correct)\n",
    "print(float(correct) / len(dev_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_X = Variable(torch.from_numpy(test_X).contiguous())\n",
    "testing_y = Variable(torch.from_numpy(np.asarray(test_y)).contiguous()).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6482681444723833\n",
      "76\n",
      "0.76\n"
     ]
    }
   ],
   "source": [
    "test_pred = net(testing_X)\n",
    "print(critetion(test_pred, testing_y).data[0])\n",
    "\n",
    "# check how many we got right:\n",
    "correct = 0\n",
    "for ii, pred in enumerate(test_pred.data):\n",
    "    i = np.argmax(pred)\n",
    "    if i == test_y[ii]:\n",
    "        correct += 1\n",
    "        \n",
    "        \n",
    "print(correct)\n",
    "print(float(correct) / len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
